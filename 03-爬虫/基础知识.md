# 库(library)
## 一、requests
1. 导入模块
2. 发送get请求,获取响应
3. 从响应中获取数据

```python
# get
response = request.get(curl [,headers=])

# post
print(response.content.decode([encoding='utf8']))
# default
< response [code] >
```

response : 响应
request : 请求
encoding : 编码
decoding : 解码
self : 自我
**attr**ibute : 属性
recursive : 递归
compile : 搜集

pattern : 模式
matches : 匹配
## 二、bs4 & lxml
### 2.BeautifulSoup
1. 导入模块
2. 创建BeautifulSoup对象
```python
from bs4 import BeautifulSoup

soup = BeautifulSoup("<html>data</html>" [,'lxml'])
print(soup)
```

#### 2.1.find方法(搜索文档数)
1. 导入模块
2. 创建BeautifulSoup对象
3. 查找title标签
参数
- name : 标签名
- attrs : 属性字典
- recursive : 是否递归循环查找
- text : 根据文本内容查找
返回值
	查找到的第一个匀速对象
```python
# 查找第一个
find(self, name=None [,attrs={}, recursive=True, string=None, **Kwargs])

# 查找全部
find_all()


# 按标签查找(查找title标签)
print(soup.find("title"))

# 按类名查找(查找center类)
print(soup.find(attrs={"center"}))

# 按内容查找
## 精确匹配text
print(soup.find(string="text"))

## 模糊匹配
import re
print (soup.find(string=re.conpile("text")))
```
#### 2.2.tag对象常见属性
- name : 获取标签名称
- attrs : 获取标签所有属性的键和值
- text : 获取标签的文本字符串
```python
soup.find('title').name

soup.find('title').attrs

soup.find('title').text
```

# 正则表达式(regular expression)
## 基础知识
### 单个字符(只匹配一次)
\[] : a\[c] 只匹配出==ac==
### 预定义字符集

| 符号  | 含义                     | 案例             |
| --- | ---------------------- | -------------- |
| \d  | \[0-9]                 | a\dc : a5c     |
| \D  | \[^\d]                 | a\Dc : abc     |
| \s  | 空白字符(空格,\t,\r,\n,\f\v) | a\sc : a c     |
| \S  | 非空白字符\[^\s]            | a\Sc : abc     |
| \w  | 单词字符\[A-Za-z0-9]       | a\wc : abc,a5c |
| \W  | 非单词字符\[^A-Za-a0-9]     | a\Wc : a c     |
### 量词(前一个字符)

| 符号  | 含义   | 案例                    |
| --- | ---- | --------------------- |
| \*  | 0或无限 | a\*c : c ,ac, aac,... |
| +   | 1或无限 | a+c : ac, aac,...     |
| ?   | 0或1  | a?c : c, ac           |
| {m} | m次   | a{1}c : ac            |



## re库
```python
import re

string =  "string"
Pattern = "regular_expression"

rs = re.findall(Pattern, string)
```